{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Libraries\" data-toc-modified-id=\"Libraries-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Libraries</a></span></li><li><span><a href=\"#Data\" data-toc-modified-id=\"Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data</a></span></li><li><span><a href=\"#Parse-the-data\" data-toc-modified-id=\"Parse-the-data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Parse the data</a></span></li><li><span><a href=\"#Data-Exploration\" data-toc-modified-id=\"Data-Exploration-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Data Exploration</a></span></li><li><span><a href=\"#Pre-processing-Functions\" data-toc-modified-id=\"Pre-processing-Functions-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Pre-processing Functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Look-up-Table\" data-toc-modified-id=\"Look-up-Table-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Look-up Table</a></span></li><li><span><a href=\"#Tokenize-Punctuation\" data-toc-modified-id=\"Tokenize-Punctuation-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Tokenize Punctuation</a></span></li><li><span><a href=\"#Apply-the-pre-processing-functions\" data-toc-modified-id=\"Apply-the-pre-processing-functions-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Apply the pre-processing functions</a></span></li></ul></li><li><span><a href=\"#Neural-Network\" data-toc-modified-id=\"Neural-Network-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Neural Network</a></span><ul class=\"toc-item\"><li><span><a href=\"#Input:-Batching\" data-toc-modified-id=\"Input:-Batching-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Input: Batching</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data/seinfeld-chronicles/scripts.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Character</th>\n",
       "      <th>Dialogue</th>\n",
       "      <th>EpisodeNo</th>\n",
       "      <th>SEID</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>JERRY</td>\n",
       "      <td>Do you know what this is all about? Do you kno...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>S01E01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>JERRY</td>\n",
       "      <td>(pointing at Georges shirt) See, to me, that b...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>S01E01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>GEORGE</td>\n",
       "      <td>Are you through?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>S01E01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>JERRY</td>\n",
       "      <td>You do of course try on, when you buy?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>S01E01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>GEORGE</td>\n",
       "      <td>Yes, it was purple, I liked it, I dont actuall...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>S01E01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Character                                           Dialogue  \\\n",
       "0           0     JERRY  Do you know what this is all about? Do you kno...   \n",
       "1           1     JERRY  (pointing at Georges shirt) See, to me, that b...   \n",
       "2           2    GEORGE                                   Are you through?   \n",
       "3           3     JERRY             You do of course try on, when you buy?   \n",
       "4           4    GEORGE  Yes, it was purple, I liked it, I dont actuall...   \n",
       "\n",
       "   EpisodeNo    SEID  Season  \n",
       "0        1.0  S01E01     1.0  \n",
       "1        1.0  S01E01     1.0  \n",
       "2        1.0  S01E01     1.0  \n",
       "3        1.0  S01E01     1.0  \n",
       "4        1.0  S01E01     1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scripts_df = pd.read_csv(data_dir)\n",
    "scripts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse the data\n",
    "Desired format:\n",
    "<br>\n",
    "all one string, with the character name, colon, then lower-cased dialoge. \n",
    "<br>\n",
    "Example\n",
    "<br>\n",
    "'jerry:  do you know what this is all about? do you know, why were here?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to format text\n",
    "def scriptParser(character, dialogue):\n",
    "    if(isinstance(dialogue, str)):\n",
    "        dialogue = dialogue.lower()\n",
    "    else:\n",
    "        #dialogue = str(dialogue)\n",
    "        #print(dialogue) - always a nan\n",
    "        dialogue = ''\n",
    "    if(isinstance(character, str)):\n",
    "        character = character.lower()\n",
    "    else:\n",
    "        #character = str(character)\n",
    "        character = ''\n",
    "    \n",
    "    return character+': '+dialogue+'\\n\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jerry: do you know what this is all about? do you know, why were here? to be out, this is out...and out is one of the single most enjoyable experiences of life. people...did you ever hear people talking about we should go out? this is what theyre talking about...this whole thing, were all out now, no one is home. not one person here is home, were all out! there are people tryin to find us, they dont know where we are. (on an imaginary phone) did you ring?, i cant find him. where did he go? he didnt tell me where he was going. he must have gone out. you wanna go out you get ready, you pick out the clothes, right? you take the shower, you get all ready, get the cash, get your friends, the car, the spot, the reservation...then youre standing around, whatta you do? you go we gotta be getting back. once youre out, you wanna get back! you wanna go to sleep, you wanna get up, you wanna go out again tomorrow, right? where ever you are in life, its my feeling, youve gotta go.\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the function on one row\n",
    "row = 0\n",
    "scriptParser(scripts_df['Character'].iloc[row], scripts_df['Dialogue'].iloc[row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jerry: do you know what this is all about? do you know, why were here? to be out, this is out...and out is one of the single most enjoyable experiences of life. people...did you ever hear people talking about we should go out? this is what theyre talking about...this whole thing, were all out now, no one is home. not one person here is home, were all out! there are people tryin to find us, they dont know where we are. (on an imaginary phone) did you ring?, i cant find him. where did he go? he didnt tell me where he was going. he must have gone out. you wanna go out you get ready, you pick out the clothes, right? you take the shower, you get all ready, get the cash, get your friends, the car, the spot, the reservation...then youre standing around, whatta you do? you go we gotta be getting back. once youre out, you wanna get back! you wanna go to sleep, you wanna get up, you wanna go out again tomorrow, right? where ever you are in life, its my feeling, youve gotta go.\\n\\njerry: (pointing at georges shirt) see, to me, that button is in the worst possible spot. the second button literally makes or breaks the shirt, look at it. its too high! its in no-mans-land. you look like you live with your mother.\\n\\ngeorge: are you through?\\n\\njerry: you do of course try on, when you buy?\\n\\ngeorge: yes, it was purple, i liked it, i dont actually recall considering the buttons.\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the function while joining on 5 rows\n",
    "''.join([scriptParser(row['Character'], row['Dialogue']) \n",
    "         for index, row in scripts_df[:5].iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the function\n",
    "text = ''.join([scriptParser(row['Character'], row['Dialogue']) \n",
    "         for index, row in scripts_df.iterrows()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Stats\n",
      "~ Number of unique words: 46380\n",
      "Number of lines: 109233\n",
      "Average number of words in each line: 5.544121282030155\n",
      "\n",
      "The lines 0 to 10:\n",
      "jerry: do you know what this is all about? do you know, why were here? to be out, this is out...and out is one of the single most enjoyable experiences of life. people...did you ever hear people talking about we should go out? this is what theyre talking about...this whole thing, were all out now, no one is home. not one person here is home, were all out! there are people tryin to find us, they dont know where we are. (on an imaginary phone) did you ring?, i cant find him. where did he go? he didnt tell me where he was going. he must have gone out. you wanna go out you get ready, you pick out the clothes, right? you take the shower, you get all ready, get the cash, get your friends, the car, the spot, the reservation...then youre standing around, whatta you do? you go we gotta be getting back. once youre out, you wanna get back! you wanna go to sleep, you wanna get up, you wanna go out again tomorrow, right? where ever you are in life, its my feeling, youve gotta go.\n",
      "\n",
      "jerry: (pointing at georges shirt) see, to me, that button is in the worst possible spot. the second button literally makes or breaks the shirt, look at it. its too high! its in no-mans-land. you look like you live with your mother.\n",
      "\n",
      "george: are you through?\n",
      "\n",
      "jerry: you do of course try on, when you buy?\n",
      "\n",
      "george: yes, it was purple, i liked it, i dont actually recall considering the buttons.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "view_line_range = (0, 10)\n",
    "\n",
    "print('Dataset Stats')\n",
    "print('~ Number of unique words: {}'.format(len({word: None for word in text.split()})))\n",
    "\n",
    "lines = text.split('\\n')\n",
    "print('Number of lines: {}'.format(len(lines)))\n",
    "word_count_line = [len(line.split()) for line in lines]\n",
    "print('Average number of words in each line: {}'.format(np.average(word_count_line)))\n",
    "\n",
    "print()\n",
    "print('The lines {} to {}:'.format(*view_line_range))\n",
    "print('\\n'.join(text.split('\\n')[view_line_range[0]:view_line_range[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look-up Table\n",
    "2 dictionaries:\n",
    "<br>\n",
    "1. word to index: words2idx \n",
    "2. index to word: idx2word \n",
    "\n",
    "More common words should have a lower index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lookup_tables(text):\n",
    "    \"\"\"\n",
    "    Create lookup tables for vocabulary\n",
    "    \n",
    "    text: The text of tv scripts split into words\n",
    "    returns: A tuple of dicts (vocab_to_int, int_to_vocab)\n",
    "    \"\"\"\n",
    "    # first get the word_counts\n",
    "    word_counts = Counter(text)\n",
    "    \n",
    "    # sort from most to least frequent\n",
    "    sorted_vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "    \n",
    "    # define the dictionaries\n",
    "    idx2word = {ii: word for ii, word in enumerate(sorted_vocab)}\n",
    "    word2idx = {word: ii for ii, word in idx2word.items()}\n",
    "    \n",
    "    # return tuple\n",
    "    return (idx2word, word2idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dict to turn punctuation into a token.\n",
    "punct2token = {'.': '<PERIOD>',\n",
    "                ',': '<COMMA>',\n",
    "                '\"': '<QUOTATION_MARK>',\n",
    "                ';': '<SEMICOLON>',\n",
    "                '!': '<EXCLAMATION_MARK>',\n",
    "                '?': '<QUESTION_MARK>',\n",
    "                '(': '<LEFT_PAREN>',\n",
    "                ')': '<RIGHT_PAREN>',\n",
    "                '--': ' <HYPHENS> ',\n",
    "                '-': '<DASH>',\n",
    "                '?': '<QUESTION_MARK>',\n",
    "                '\\n': '<NEW_LINE>',\n",
    "                ':': ' <COLON> '}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<COMMA>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punct2token[',']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the pre-processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the punctuation\n",
    "for punct, token in punct2token.items():\n",
    "    text = text.replace(punct, ' {} '.format(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split and make all ensure all text is lower case\n",
    "text = text.lower()\n",
    "text = text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the vocab dictionaries\n",
    "idx2word, word2idx = create_lookup_tables(text + ['<PAD>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply dictionaries to text\n",
    "int_text = [word2idx[word] for word in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to a pickle file\n",
    "pickle.dump((int_text, idx2word, word2idx, punct2token), open('preprocess.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found. Please use a GPU to train your neural network.\n"
     ]
    }
   ],
   "source": [
    "# Check GPU Access\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if not train_on_gpu:\n",
    "    print('No GPU found. Please use a GPU to train your neural network.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input: Batching\n",
    "We want to batch the data based on a provided sequence legnth\n",
    "Example Input:\n",
    "```\n",
    "words = [1, 2, 3, 4, 5, 6, 7]\n",
    "sequence_length = 4\n",
    "```\n",
    "\n",
    "`features` Tensor:\n",
    "```\n",
    "[1, 2, 3, 4]\n",
    "```\n",
    "`target` Tensor (the next \"word\"):\n",
    "```\n",
    "5\n",
    "```\n",
    "\n",
    "Next `features` and `target` Tensors:\n",
    "```\n",
    "[2, 3, 4, 5]  # features\n",
    "6             # target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data(words, sequence_length, batch_size):\n",
    "    \"\"\"\n",
    "    Batch the neural network data using DataLoader\n",
    "    param words: The word ids of the TV scripts\n",
    "    param sequence_length: The sequence length of each batch\n",
    "    param batch_size: The size of each batch; the number of sequences in a batch\n",
    "    return: DataLoader with batched data\n",
    "    \"\"\"\n",
    "    # calculate the number of batches in the data set\n",
    "    num_batches = int(len(words) / (sequence_length+1))\n",
    "    \n",
    "    # restrict 'words' to an even number of batches\n",
    "    #words = words[:(num_batches*batch_size)]\n",
    "    \n",
    "    # first use a DataLoader to batch the words into segments of sequnce + 1 for target\n",
    "    #word_dL = DataLoader(words, shuffle=False, batch_size=sequence_length+1)\n",
    "    \n",
    "    # initialize empty nd arrays to store the batched features & target words\n",
    "    features = np.zeros([num_batches+1, sequence_length])\n",
    "    targets = np.zeros([num_batches+1, 1])\n",
    "\n",
    "    # iterate overall all word batches\n",
    "    for i, word_batch in enumerate(word_dL):\n",
    "        features[i,:] = np.array(word_batch[:-1])\n",
    "        targets[i] = np.array(word_batch[-1:])\n",
    "    \n",
    "    # convert numpy arrays into a torch tensor dataset\n",
    "    sequenced_data = TensorDataset(torch.from_numpy(features), torch.from_numpy(targets))\n",
    "    \n",
    "    # create the final batch DataLoader\n",
    "    batch_dL = DataLoader(sequenced_data, shuffle=True, batch_size=batch_size) \n",
    "\n",
    "    # return a dataloader\n",
    "    return batch_dL\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 5])\n",
      "tensor([[ 0.,  1.,  2.,  3.,  4.],\n",
      "        [ 6.,  7.,  8.,  9., 10.],\n",
      "        [12., 13., 14., 15., 16.],\n",
      "        [18., 19., 20., 21., 22.],\n",
      "        [24., 25., 26., 27., 28.],\n",
      "        [30., 31., 32., 33., 34.],\n",
      "        [36., 37., 38., 39., 40.],\n",
      "        [42., 43., 44., 45., 46.],\n",
      "        [48., 48., 48., 48., 48.]], dtype=torch.float64)\n",
      "\n",
      "torch.Size([9, 1])\n",
      "tensor([[ 5.],\n",
      "        [11.],\n",
      "        [17.],\n",
      "        [23.],\n",
      "        [29.],\n",
      "        [35.],\n",
      "        [41.],\n",
      "        [47.],\n",
      "        [49.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "test_text = range(50)\n",
    "t_loader = batch_data(test_text, sequence_length=5, batch_size=10)\n",
    "\n",
    "data_iter = iter(t_loader)\n",
    "sample_x, sample_y = data_iter.next()\n",
    "\n",
    "print(sample_x.shape)\n",
    "print(sample_x)\n",
    "print()\n",
    "print(sample_y.shape)\n",
    "print(sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.random([5, 10])\n",
    "y = np.array([1, 2, 3, 4, 5])\n",
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = TensorDataset(torch.from_numpy(x), torch.from_numpy(y))\n",
    "dL = DataLoader(test_data,  shuffle=False, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3414, 0.4809, 0.5231, 0.0827, 0.4757, 0.7977, 0.7831, 0.5836, 0.9946,\n",
      "         0.5022],\n",
      "        [0.5494, 0.8426, 0.0129, 0.5212, 0.1126, 0.5043, 0.9004, 0.6469, 0.5160,\n",
      "         0.4610]], dtype=torch.float64)\n",
      "tensor([1, 2], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "sample_x, sample_y = iter(dL).next()\n",
    "print(sample_x)\n",
    "print(sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterable = iter(dL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[0.2159, 0.9008, 0.7186, 0.4760, 0.9190, 0.1269, 0.9605, 0.7384, 0.4816,\n",
      "         0.6621]], dtype=torch.float64), tensor([1], dtype=torch.int32)]\n",
      "[tensor([[0.6120, 0.7709, 0.8076, 0.5105, 0.2908, 0.7646, 0.1350, 0.5464, 0.0268,\n",
      "         0.5985]], dtype=torch.float64), tensor([2], dtype=torch.int32)]\n",
      "[tensor([[0.6235, 0.9492, 0.6565, 0.1241, 0.4754, 0.0743, 0.6031, 0.5243, 0.1634,\n",
      "         0.2615]], dtype=torch.float64), tensor([3], dtype=torch.int32)]\n",
      "[tensor([[0.3496, 0.4543, 0.2918, 0.7355, 0.5186, 0.2635, 0.1392, 0.8167, 0.2160,\n",
      "         0.9728]], dtype=torch.float64), tensor([4], dtype=torch.int32)]\n",
      "[tensor([[0.8694, 0.8113, 0.9105, 0.7424, 0.6644, 0.1095, 0.6783, 0.8121, 0.1253,\n",
      "         0.4813]], dtype=torch.float64), tensor([5], dtype=torch.int32)]\n"
     ]
    }
   ],
   "source": [
    "for i, x in enumerate(dL):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "331px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
